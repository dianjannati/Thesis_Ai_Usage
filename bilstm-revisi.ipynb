{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Bi-LSTM"
      ],
      "metadata": {
        "id": "p0yxyK0wy08U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import regularizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Bidirectional, SpatialDropout1D, Dropout, BatchNormalization\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "df_tweets = pd.read_csv(\"tweets-clean.csv\", sep=\";\")\n",
        "\n",
        "df_tweets['clean_content'] = (\n",
        "    df_tweets['clean_content']\n",
        "    .str.replace(r'\\b(temp|hyphen)\\b', '', regex=True)\n",
        "    .str.replace(r'\\s+', ' ', regex=True)\n",
        "    .str.strip()\n",
        ")\n",
        "\n",
        "print(\"Total data:\", len(df_tweets))\n",
        "\n",
        "max_words = 4000\n",
        "max_len = 30\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words, lower=True, split=' ')\n",
        "tokenizer.fit_on_texts(df_tweets['clean_content'].values.astype('U'))\n",
        "X = tokenizer.texts_to_sequences(df_tweets['clean_content'].values.astype('U'))\n",
        "X = pad_sequences(X, maxlen=max_len)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df_tweets['polarity'])\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=42)\n",
        "\n",
        "!wget -q https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.id.300.vec.gz\n",
        "!gunzip -f cc.id.300.vec.gz\n",
        "\n",
        "embeddings_index = {}\n",
        "with open('cc.id.300.vec', encoding='utf-8') as f:\n",
        "    next(f)\n",
        "    for line in f:\n",
        "        values = line.rstrip().split(' ')\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(f\"Found {len(embeddings_index)} word vectors.\")\n",
        "\n",
        "embedding_dim = 300\n",
        "word_index = tokenizer.word_index\n",
        "num_words = min(max_words, len(word_index) + 1)\n",
        "\n",
        "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    if i < max_words:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "\n",
        "lstm_units = 128\n",
        "dropout_rate = 0.45\n",
        "trainable_embed = False\n",
        "\n",
        "bi_model = Sequential([\n",
        "    Embedding(\n",
        "        input_dim=num_words,\n",
        "        output_dim=embedding_dim,\n",
        "        weights=[embedding_matrix],\n",
        "        input_length=max_len,\n",
        "        trainable=trainable_embed\n",
        "    ),\n",
        "    SpatialDropout1D(0.3),\n",
        "    Bidirectional(LSTM(lstm_units, dropout=0.3, recurrent_dropout=0.3)),\n",
        "    Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(dropout_rate),\n",
        "    Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "bi_model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "bi_model.summary()\n",
        "\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "model_checkpoint_callback = ModelCheckpoint('best_bilstm.weights.h5', save_weights_only=True, monitor='val_loss', save_best_only=True)\n",
        "\n",
        "history = bi_model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=20,\n",
        "    batch_size=8,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[early_stopping_callback, model_checkpoint_callback],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "y_pred = bi_model.predict(X_test, batch_size=8, verbose=1)\n",
        "y_pred_classes = y_pred.argmax(axis=-1)\n",
        "y_true = y_test.argmax(axis=-1)\n",
        "\n",
        "print(\"\\n=== Evaluation Results ===\")\n",
        "print(\"Accuracy:\", round(accuracy_score(y_true, y_pred_classes), 4))\n",
        "print(classification_report(y_true, y_pred_classes, target_names=label_encoder.classes_))\n"
      ],
      "metadata": {
        "id": "dddGbTVGy3oL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fd6dd516-f7f7-4436-84c2-6c81ef29a7bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total data: 2726\n",
            "Found 2000000 word vectors.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │     \u001b[38;5;34m1,200,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ spatial_dropout1d_4             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_4 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,200,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ spatial_dropout1d_4             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,200,000\u001b[0m (4.58 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,200,000</span> (4.58 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,200,000\u001b[0m (4.58 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,200,000</span> (4.58 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 213ms/step - accuracy: 0.3785 - loss: 2.7807 - val_accuracy: 0.4340 - val_loss: 2.0537\n",
            "Epoch 2/20\n",
            "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 212ms/step - accuracy: 0.4531 - loss: 1.9797 - val_accuracy: 0.5355 - val_loss: 1.5895\n",
            "Epoch 3/20\n",
            "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 208ms/step - accuracy: 0.4939 - loss: 1.5495 - val_accuracy: 0.5685 - val_loss: 1.3147\n",
            "Epoch 4/20\n",
            "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 209ms/step - accuracy: 0.5352 - loss: 1.3123 - val_accuracy: 0.5587 - val_loss: 1.1892\n",
            "Epoch 5/20\n",
            "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 218ms/step - accuracy: 0.5459 - loss: 1.1703 - val_accuracy: 0.5697 - val_loss: 1.0886\n",
            "Epoch 6/20\n",
            "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 208ms/step - accuracy: 0.5500 - loss: 1.0773 - val_accuracy: 0.5685 - val_loss: 1.0227\n",
            "Epoch 7/20\n",
            "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 215ms/step - accuracy: 0.5649 - loss: 1.0016 - val_accuracy: 0.5819 - val_loss: 1.0072\n",
            "Epoch 8/20\n",
            "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 214ms/step - accuracy: 0.5923 - loss: 0.9529 - val_accuracy: 0.5966 - val_loss: 0.9642\n",
            "Epoch 9/20\n",
            "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 208ms/step - accuracy: 0.6044 - loss: 0.9252 - val_accuracy: 0.5709 - val_loss: 0.9778\n",
            "Epoch 10/20\n",
            "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 209ms/step - accuracy: 0.5836 - loss: 0.9343 - val_accuracy: 0.5685 - val_loss: 0.9787\n",
            "Epoch 11/20\n",
            "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 217ms/step - accuracy: 0.6086 - loss: 0.9066 - val_accuracy: 0.6051 - val_loss: 0.9308\n",
            "Epoch 12/20\n",
            "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 208ms/step - accuracy: 0.5858 - loss: 0.9105 - val_accuracy: 0.6002 - val_loss: 0.9448\n",
            "Epoch 13/20\n",
            "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 209ms/step - accuracy: 0.6283 - loss: 0.8926 - val_accuracy: 0.6161 - val_loss: 0.8935\n",
            "Epoch 14/20\n",
            "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 216ms/step - accuracy: 0.6246 - loss: 0.8898 - val_accuracy: 0.6149 - val_loss: 0.9521\n",
            "Epoch 15/20\n",
            "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 209ms/step - accuracy: 0.6432 - loss: 0.8571 - val_accuracy: 0.5990 - val_loss: 0.9564\n",
            "Epoch 16/20\n",
            "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 211ms/step - accuracy: 0.6169 - loss: 0.8991 - val_accuracy: 0.5905 - val_loss: 0.9365\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step\n",
            "\n",
            "=== Evaluation Results ===\n",
            "Accuracy: 0.6161\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.61      0.87      0.71       355\n",
            "     neutral       0.61      0.43      0.51       266\n",
            "    positive       0.67      0.41      0.50       197\n",
            "\n",
            "    accuracy                           0.62       818\n",
            "   macro avg       0.63      0.57      0.58       818\n",
            "weighted avg       0.62      0.62      0.60       818\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 5093593,
          "sourceId": 8529071,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30699,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}